{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "2-Sentiment analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E93IzUO8ZdqR",
        "colab_type": "text"
      },
      "source": [
        "<div style=\"width: 100%; clear: both;\">\n",
        "<div style=\"float: left; width: 50%;\">\n",
        "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
        "</div>\n",
        "<div style=\"float: right; width: 50%;\">\n",
        "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
        "</div>\n",
        "</div>\n",
        "<div style=\"width:100%;\">&nbsp;</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOtuLCmUZdqS",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment analysis\n",
        "\n",
        "Veremos dos modelos o implementaciones distintas:\n",
        "\n",
        "- Basado en diccionario\n",
        "- Basado en métodos de aprendizaje automático (machine learning, ML)\n",
        "\n",
        "El conjunto de datos sobre el que trabajaremos está disponible en: \n",
        "https://www.kaggle.com/welkin10/airline-sentiment\n",
        "\n",
        "Estos son datos de aerolíneas de EE. UU. que contienen comentarios de pasajeros sobre la base del servicio proporcionado por las aerolíneas, donde nos interesa poder clasificar los comentarios según sean positivos o negativos.\n",
        "\n",
        "El conjunto de datos contiene:\n",
        "\n",
        "- 14.640 comentarios etiquetados\n",
        "- 15 atributos, incluyendo la polaridad del comentario"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUxGeZhSZdqT",
        "colab_type": "text"
      },
      "source": [
        "## Pre-procesamiento de los datos\n",
        "\n",
        "En primer lugar, y antes de realizar cualquier tipo de análisis, es común (y muy útil) realizar una serie de procesos sobre el texto para mejorar los análisis posteriores. \n",
        "\n",
        "En concreto, estos procesos se pueden dividir en 3 bloques:\n",
        "\n",
        "- Tokenización del texto\n",
        "- Eliminación de las *stopwords*\n",
        "- Stemming (obtención de la palabra raíz)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KquMJ1ZXZdqU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "ad8bdedd-5971-4869-94ae-a8c54bdf701c"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "dataset = pd.read_csv(\"https://raw.githubusercontent.com/kolaveridi/kaggle-Twitter-US-Airline-Sentiment-/master/Tweets.csv\", encoding=\"ISO-8859-1\")\n",
        "\n",
        "print(\"Dataset shape is {}\".format(dataset.shape))\n",
        "dataset.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset shape is (14640, 15)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...               user_timezone\n",
              "0  570306133677760513  ...  Eastern Time (US & Canada)\n",
              "1  570301130888122368  ...  Pacific Time (US & Canada)\n",
              "2  570301083672813571  ...  Central Time (US & Canada)\n",
              "3  570301031407624196  ...  Pacific Time (US & Canada)\n",
              "4  570300817074462722  ...  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKL2_qSeZdqX",
        "colab_type": "text"
      },
      "source": [
        "Deberemos instalar la librería \"nltk\" de procesamiento de lenguaje natural, y descargar el conjunto de datos eqtiquetado como \"stopwords\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSXcK1htZdqY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "93877ce1-5306-4511-b659-4dbc4a36c61f"
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZFjPkWRZdqa",
        "colab_type": "text"
      },
      "source": [
        "Cargamos los atributos \"text\" (que contiene el texto del tweet) y \"airline_sentiment\" (que contiene la polaridad del tweet).\n",
        "\n",
        "Además, cargamos:\n",
        "\n",
        "- las *stopwords* (en inglés) \n",
        "- y la clase que realizará el *stemmer* (que es un proceso automatizado que produce una cadena de base en un intento de representar palabras relacionadas)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxPP3LKcZdqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "tweets = dataset.text\n",
        "results = dataset.airline_sentiment\n",
        "english_stopwords = set(stopwords.words('english'))\n",
        "stemmer = SnowballStemmer('english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqjxFUAUZdqd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "62a3f624-b89f-4a47-e122-c471742d7540"
      },
      "source": [
        "for i in range(5):\n",
        "    print(\"[%d] [%s\\t]: %s\" % (i, results[i], tweets[i]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0] [neutral\t]: @VirginAmerica What @dhepburn said.\n",
            "[1] [positive\t]: @VirginAmerica plus you've added commercials to the experience... tacky.\n",
            "[2] [neutral\t]: @VirginAmerica I didn't today... Must mean I need to take another trip!\n",
            "[3] [negative\t]: @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse\n",
            "[4] [negative\t]: @VirginAmerica and it's a really big bad thing about it\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v2ypCdcZdqf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "613d4daf-23a5-4fbd-de38-bafb165a16a7"
      },
      "source": [
        "print(\"Stop words [num=%d] and sample is %s\" % ((len(english_stopwords), list(english_stopwords)[0:5])))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stop words [num=179] and sample is [\"you'd\", 'between', 'about', 'is', \"you've\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w8fhsY4Zdqi",
        "colab_type": "text"
      },
      "source": [
        "### Step 1 - Tokenize\n",
        "\n",
        "La primera técnica a aplicar es la tokenización, la cual consiste en separar un texto por palabras, sentencias o conjunto de palabras. En este caso, como que los tweets son frases cortas, se ha separado por palabras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWEBnGzTZdqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_tokenizing(txts):\n",
        "    regexT = RegexpTokenizer('[a-zA-Z\\']+')\n",
        "    txts_tokenized = []\n",
        "    \n",
        "    for txt in txts:\n",
        "        a = regexT.tokenize(txt)\n",
        "        txts_tokenized.append(a)\n",
        "    return(txts_tokenized)\n",
        "\n",
        "tweets_tokenized = word_tokenizing(tweets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfHf31oBZdqk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "2aff4719-266e-4eba-b1e9-8d955f6a1b91"
      },
      "source": [
        "for i in range(5):\n",
        "    print(\"[%d] -> %s\\n    <- %s\" % (i, tweets_tokenized[i], tweets[i]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0] -> ['VirginAmerica', 'What', 'dhepburn', 'said']\n",
            "    <- @VirginAmerica What @dhepburn said.\n",
            "[1] -> ['VirginAmerica', 'plus', \"you've\", 'added', 'commercials', 'to', 'the', 'experience', 'tacky']\n",
            "    <- @VirginAmerica plus you've added commercials to the experience... tacky.\n",
            "[2] -> ['VirginAmerica', 'I', \"didn't\", 'today', 'Must', 'mean', 'I', 'need', 'to', 'take', 'another', 'trip']\n",
            "    <- @VirginAmerica I didn't today... Must mean I need to take another trip!\n",
            "[3] -> ['VirginAmerica', \"it's\", 'really', 'aggressive', 'to', 'blast', 'obnoxious', 'entertainment', 'in', 'your', \"guests'\", 'faces', 'amp', 'they', 'have', 'little', 'recourse']\n",
            "    <- @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse\n",
            "[4] -> ['VirginAmerica', 'and', \"it's\", 'a', 'really', 'big', 'bad', 'thing', 'about', 'it']\n",
            "    <- @VirginAmerica and it's a really big bad thing about it\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7Kiur_7Zdqn",
        "colab_type": "text"
      },
      "source": [
        "### Step 2 - Remove StopWords\n",
        "\n",
        "Una vez tenemos el conjunto de palabras por separado, hay que eliminar las llamadas *stopwords*, que son palabras muy frecuentes pero no tienen ninguna información semántica, como por ejemplo los determinantes y adverbios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMlvu2aeZdqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stopword_removal(txts):\n",
        "    t_s = []\n",
        "    tweets_stopword = []\n",
        "    \n",
        "    for txt in txts:\n",
        "        for word in txt:\n",
        "            if word not in english_stopwords:\n",
        "                t_s.append(word)\n",
        "        tweets_stopword.append(t_s)\n",
        "        t_s = []\n",
        "    return(tweets_stopword)\n",
        "\n",
        "tweets_stopword = stopword_removal(tweets_tokenized)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4TyFONBZdqp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "13335a1a-3f9a-4410-bd4d-85b53871e832"
      },
      "source": [
        "for i in range(5):\n",
        "    print(\"[%d] -> %s\\n    <- %s\" % (i, tweets_stopword[i], tweets_tokenized[i]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0] -> ['VirginAmerica', 'What', 'dhepburn', 'said']\n",
            "    <- ['VirginAmerica', 'What', 'dhepburn', 'said']\n",
            "[1] -> ['VirginAmerica', 'plus', 'added', 'commercials', 'experience', 'tacky']\n",
            "    <- ['VirginAmerica', 'plus', \"you've\", 'added', 'commercials', 'to', 'the', 'experience', 'tacky']\n",
            "[2] -> ['VirginAmerica', 'I', 'today', 'Must', 'mean', 'I', 'need', 'take', 'another', 'trip']\n",
            "    <- ['VirginAmerica', 'I', \"didn't\", 'today', 'Must', 'mean', 'I', 'need', 'to', 'take', 'another', 'trip']\n",
            "[3] -> ['VirginAmerica', 'really', 'aggressive', 'blast', 'obnoxious', 'entertainment', \"guests'\", 'faces', 'amp', 'little', 'recourse']\n",
            "    <- ['VirginAmerica', \"it's\", 'really', 'aggressive', 'to', 'blast', 'obnoxious', 'entertainment', 'in', 'your', \"guests'\", 'faces', 'amp', 'they', 'have', 'little', 'recourse']\n",
            "[4] -> ['VirginAmerica', 'really', 'big', 'bad', 'thing']\n",
            "    <- ['VirginAmerica', 'and', \"it's\", 'a', 'really', 'big', 'bad', 'thing', 'about', 'it']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvrlibwTZdqr",
        "colab_type": "text"
      },
      "source": [
        "### Step 3 - Stemming\n",
        "\n",
        "La técnica conocida como *stemming* es el proceso de transformar las palabras a su forma raíz. De esta forma mantenemos la semántica y unificamos todas las palabras derivadas a una única palabra (la raíz)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmsacDkZZdqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stemming(txts):\n",
        "    tweets_stemmed = []\n",
        "    \n",
        "    for txt in txts:\n",
        "        stem = []\n",
        "        for word in txt:\n",
        "            stem.append(stemmer.stem(word))\n",
        "        tweets_stemmed.append(stem)\n",
        "    \n",
        "    return(tweets_stemmed)\n",
        "\n",
        "tweets_stemmed = stemming(tweets_stopword)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw5Nq6dgZdqu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a46f780a-faa5-4e76-b514-a8a550415cdf"
      },
      "source": [
        "for i in range(5):\n",
        "    print(\"[%d] -> %s\\n    <- %s\" % (i, tweets_stemmed[i], tweets_stopword[i]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0] -> ['virginamerica', 'what', 'dhepburn', 'said']\n",
            "    <- ['VirginAmerica', 'What', 'dhepburn', 'said']\n",
            "[1] -> ['virginamerica', 'plus', 'ad', 'commerci', 'experi', 'tacki']\n",
            "    <- ['VirginAmerica', 'plus', 'added', 'commercials', 'experience', 'tacky']\n",
            "[2] -> ['virginamerica', 'i', 'today', 'must', 'mean', 'i', 'need', 'take', 'anoth', 'trip']\n",
            "    <- ['VirginAmerica', 'I', 'today', 'Must', 'mean', 'I', 'need', 'take', 'another', 'trip']\n",
            "[3] -> ['virginamerica', 'realli', 'aggress', 'blast', 'obnoxi', 'entertain', 'guest', 'face', 'amp', 'littl', 'recours']\n",
            "    <- ['VirginAmerica', 'really', 'aggressive', 'blast', 'obnoxious', 'entertainment', \"guests'\", 'faces', 'amp', 'little', 'recourse']\n",
            "[4] -> ['virginamerica', 'realli', 'big', 'bad', 'thing']\n",
            "    <- ['VirginAmerica', 'really', 'big', 'bad', 'thing']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Go231ySlZdqw",
        "colab_type": "text"
      },
      "source": [
        "## Sentiment Analysis\n",
        "\n",
        "Veremos dos opciones muy comunes:\n",
        "\n",
        "- Uso de dictionarios\n",
        "- Word2Vec + aprendizaje automático (Machine Learning, ML)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YETzKCKEZdqw",
        "colab_type": "text"
      },
      "source": [
        "### Opción 1: Sentiment Analysis using dictionaries\n",
        "\n",
        "En este primer caso emplearemos diccionarios para evaluar la polaridad (positivo / negativo) de las palabras que aparecen en el texto, de forma independiente.\n",
        "\n",
        "Existen multitud de diccionarios disponibles en Internet. En este caso hemos empleado los diccionarios disponibles en: \n",
        "https://www.kaggle.com/andyxie/sentiment-analysis-dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dISjNzOZdqx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7c27de26-9148-4687-db23-d6b81a08efae"
      },
      "source": [
        "# carga de los diccionarios\n",
        "positive_words = pd.read_csv(\"https://raw.githubusercontent.com/jeffreybreen/twitter-sentiment-analysis-tutorial-201107/master/data/opinion-lexicon-English/positive-words.txt\", encoding=\"ISO-8859-1\", comment=\";\")\n",
        "negative_words = pd.read_csv(\"https://raw.githubusercontent.com/jeffreybreen/twitter-sentiment-analysis-tutorial-201107/master/data/opinion-lexicon-English/negative-words.txt\", encoding=\"ISO-8859-1\", comment=\";\")\n",
        "\n",
        "positive_words = np.resize(positive_words[:].values, len(positive_words))\n",
        "negative_words = np.resize(negative_words[:].values, len(negative_words))\n",
        "\n",
        "print(\"El diccionario positivo está formado por {} palabras\".format(len(positive_words)))\n",
        "print(positive_words)\n",
        "print(\"El diccionario negativo está formado por {} palabras\".format(len(negative_words)))\n",
        "print(negative_words)\n",
        "\n",
        "print(\"abound\" in positive_words)\n",
        "print(\"abound\" in negative_words)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El diccionario positivo está formado por 2005 palabras\n",
            "['abound' 'abounds' 'abundance' ... 'zenith' 'zest' 'zippy']\n",
            "El diccionario negativo está formado por 4782 palabras\n",
            "['2-faces' 'abnormal' 'abolish' ... 'zealous' 'zealously' 'zombie']\n",
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-BQW8_oZdqz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64be17e2-e73e-4953-d305-b76df5a9e91c"
      },
      "source": [
        "# función para obtener el score de cada texto\n",
        "def sentiment_analysis(txts):\n",
        "    predicted = []\n",
        "\n",
        "    for txt in txts:\n",
        "        m = 0\n",
        "        for word in txt:\n",
        "            if word in positive_words:\n",
        "                m = m+1\n",
        "            elif word in negative_words:\n",
        "                m = m-1\n",
        "        \n",
        "        if m > 0:\n",
        "            label = \"positive\"\n",
        "        elif m < 0:\n",
        "            label = \"negative\"\n",
        "        else:\n",
        "            label = \"neutral\"\n",
        "        predicted.append(label)\n",
        "        \n",
        "    return(predicted)\n",
        "\n",
        "predicted = sentiment_analysis(tweets_stemmed)\n",
        "\n",
        "print(\"El resumen de la predicción es: {} positivos, {} negativos y {} neutros\"\n",
        "  .format(predicted.count('positive'), predicted.count('negative'), predicted.count('neutral')))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El resumen de la predicción es: 3963 positivos, 3819 negativos y 6858 neutros\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlNdRk4yZdq1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3dae6d5d-6a82-4a27-df0c-99adbc83cc6d"
      },
      "source": [
        "for i in range(5):\n",
        "    print(\"[%d] : Predcited: %s \\t-> Real: %s\" % (i, predicted[i], results[i]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0] : Predcited: neutral \t-> Real: neutral\n",
            "[1] : Predcited: neutral \t-> Real: positive\n",
            "[2] : Predcited: neutral \t-> Real: neutral\n",
            "[3] : Predcited: positive \t-> Real: negative\n",
            "[4] : Predcited: negative \t-> Real: negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhFug-3gZdq3",
        "colab_type": "text"
      },
      "source": [
        "A partir del número de aciertos sobre el número total de textos se define la precisión (*accuracy*) del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBo0Vwz1Zdq4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42bd7e25-d44a-4e7f-91fb-7b7287f55a35"
      },
      "source": [
        "ok = sum(predicted == results)\n",
        "total = len(results)\n",
        "\n",
        "print(\"Accuracy is %.2f%% [%d / %d]\" % ((ok / total)*100, ok, total))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is 47.53% [6959 / 14640]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrlhnVVgZdq6",
        "colab_type": "text"
      },
      "source": [
        "### Opción 2: Word2Vec + modelo ML\n",
        "\n",
        "En este segundo caso emplearemos un método un poco más complejo. \n",
        "\n",
        "Este método consiste en dos pasos principales:\n",
        "\n",
        "- Crear una matriz deonde cada fila (vector) contenga la información de un tweet\n",
        "- Crear y entrenar un modelos de aprendizaje automático (ML) que sea capaz de clasificar nuevos textos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALCrgrGqZdq7",
        "colab_type": "text"
      },
      "source": [
        "#### Crear un vector con todas las palabras pre-procesadas\n",
        "\n",
        "En concreto, crearemos un vector que nos permite obtener la siguiente información:\n",
        "\n",
        "- Crear un vector donde las columnas representan cada una (TODAS) de las palabras del vocabulario (es decir, de TODOS los textos que emplearemos)\n",
        "- Crear una nueva fila en este vector para cada uno de los textos (tweets), donde un 0 indica que la palabra representada en la columna NO aparece en el texto, y 1 que la palabra sí aparece."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nIPZ1YnZdq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets_stemmed_joined = []\n",
        "\n",
        "for tweet in tweets_stemmed:\n",
        "    tweets_stemmed_joined.append(\" \".join(str(x) for x in tweet))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UbaPoWKZdq9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "cc5bda0e-e86b-4977-8b4d-696b3965e748"
      },
      "source": [
        "for i in range(5):\n",
        "    print(\"[%d] -> %s\\n    <- %s\" % (i, tweets_stemmed_joined[i], tweets_stemmed[i]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0] -> virginamerica what dhepburn said\n",
            "    <- ['virginamerica', 'what', 'dhepburn', 'said']\n",
            "[1] -> virginamerica plus ad commerci experi tacki\n",
            "    <- ['virginamerica', 'plus', 'ad', 'commerci', 'experi', 'tacki']\n",
            "[2] -> virginamerica i today must mean i need take anoth trip\n",
            "    <- ['virginamerica', 'i', 'today', 'must', 'mean', 'i', 'need', 'take', 'anoth', 'trip']\n",
            "[3] -> virginamerica realli aggress blast obnoxi entertain guest face amp littl recours\n",
            "    <- ['virginamerica', 'realli', 'aggress', 'blast', 'obnoxi', 'entertain', 'guest', 'face', 'amp', 'littl', 'recours']\n",
            "[4] -> virginamerica realli big bad thing\n",
            "    <- ['virginamerica', 'realli', 'big', 'bad', 'thing']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWw2RuggZdq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorized_corpus = vectorizer.fit_transform(tweets_stemmed_joined)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WATlWYP0ZdrB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "06dd9d09-bc62-4fe2-f8a2-78a6913624d2"
      },
      "source": [
        "vectorized_names = vectorizer.get_feature_names()\n",
        "print(\"El vocabulario tiene una longitud de {} palabras, y un ejemplo es {}\"\n",
        "      .format(len(vectorized_names), vectorized_names[0:10]))\n",
        "\n",
        "print(\"La matriz tiene un tamaño de {}\".format(vectorized_corpus.shape))\n",
        "\n",
        "for i in range(5):\n",
        "    print(\"[%d] -> %s\\n%s\" % (i, tweets_stemmed_joined[i], vectorized_corpus[i,:]))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El vocabulario tiene una longitud de 10898 palabras, y un ejemplo es ['aa', 'aaaand', 'aaadvantag', 'aaalwaysl', 'aacustomerservic', 'aadavantag', 'aadelay', 'aadv', 'aadvantag', 'aafail']\n",
            "La matriz tiene un tamaño de (14640, 10898)\n",
            "[0] -> virginamerica what dhepburn said\n",
            "  (0, 10107)\t1\n",
            "  (0, 10337)\t1\n",
            "  (0, 2319)\t1\n",
            "  (0, 8070)\t1\n",
            "[1] -> virginamerica plus ad commerci experi tacki\n",
            "  (0, 10107)\t1\n",
            "  (0, 7178)\t1\n",
            "  (0, 89)\t1\n",
            "  (0, 1749)\t1\n",
            "  (0, 3015)\t1\n",
            "  (0, 9065)\t1\n",
            "[2] -> virginamerica i today must mean i need take anoth trip\n",
            "  (0, 10107)\t1\n",
            "  (0, 9418)\t1\n",
            "  (0, 6148)\t1\n",
            "  (0, 5783)\t1\n",
            "  (0, 6250)\t1\n",
            "  (0, 9075)\t1\n",
            "  (0, 385)\t1\n",
            "  (0, 9544)\t1\n",
            "[3] -> virginamerica realli aggress blast obnoxi entertain guest face amp littl recours\n",
            "  (0, 10107)\t1\n",
            "  (0, 7637)\t1\n",
            "  (0, 152)\t1\n",
            "  (0, 945)\t1\n",
            "  (0, 6597)\t1\n",
            "  (0, 2846)\t1\n",
            "  (0, 3900)\t1\n",
            "  (0, 3057)\t1\n",
            "  (0, 330)\t1\n",
            "  (0, 5408)\t1\n",
            "  (0, 7672)\t1\n",
            "[4] -> virginamerica realli big bad thing\n",
            "  (0, 10107)\t1\n",
            "  (0, 7637)\t1\n",
            "  (0, 893)\t1\n",
            "  (0, 672)\t1\n",
            "  (0, 9278)\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODrnUiuMZdrC",
        "colab_type": "text"
      },
      "source": [
        "#### Crear y entrenar un modelo de ML\n",
        "\n",
        "En este caso emplearemos un modelo (relativamente) simple y que ofrece (generalmente) unos buenos resultados.\n",
        "\n",
        "Las *Suport Vector Machine* o SVM son un conjunto de algoritmos de aprendizaje supervisado utilizados en problemas de clasificación y regresión. \n",
        "\n",
        "A partir de un conjunto de ejemplos de entrenamiento (etiquetados) podemos entrenar una SVM para construir un modelo que prediga la etiqueta o clase de una nueva muestra. Intuitivamente, una SVM es un modelo que representa a los puntos de la muestra en un espacio de N dimensiones, donde N es el número de atributos. El objetivo es separar las clases en espacios lo más amplios posibles mediante un hiperplano de separación.\n",
        "\n",
        "Más información en: https://en.wikipedia.org/wiki/Support-vector_machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPtMi8JiZdrD",
        "colab_type": "text"
      },
      "source": [
        "El primer paso antes de entrenar un modelo basado en aprendizaje supervisado es partir los datos en dos conjuntos disjuntos:\n",
        "\n",
        "- Conjunto de entrenamiento (*train*)\n",
        "- Conjunto de test (*test*)\n",
        "\n",
        "El conjunto de entrenamiento se utilizará para optimizar (entrenar) el modelo, mientras que el conjunto de test nos permitirá \"medir\" la precisión del modelo al predecir nuevos datos.\n",
        "\n",
        "Muchas veces se crean empleando la regla del 80-20, es decir, 80% de instancias para entrenar y 20% restante para realizar el test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOIONasXZdrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(vectorized_corpus, results\n",
        "                                                    , test_size=0.2\n",
        "                                                    , random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US4g75JrZdrF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c346e2df-1b65-47df-c6ca-6cd39d19d6e7"
      },
      "source": [
        "print(\"Train dataset shape is {}\".format(X_train.shape))\n",
        "print(\"Test dataset shape is  {}\".format(X_test.shape))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train dataset shape is (11712, 10898)\n",
            "Test dataset shape is  (2928, 10898)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvqnfFMJZdrH",
        "colab_type": "text"
      },
      "source": [
        "Una vez tenemos los conjuntos de datos creados, pasaremos a probar diferentes valores para los parámetros del modelo. \n",
        "\n",
        "En el caso de una SVM, los principales parémtros son:\n",
        "\n",
        "- *Kernel*: función que se aplica a los datos para cambiar el espacio de representación\n",
        "- *Gamma*: De manera intuitiva, el parámetro gamma define hasta dónde llega la influencia de un solo ejemplo de entrenamiento\n",
        "- *C*: El parámetro C le dice a la optimización de SVM cuánto quiere evitar errores en la clasificación de cada ejemplo de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzOw9XG2ZdrH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "19cfdc04-1228-407b-84d4-5bc6dd4c1a03"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {'C':[1,10,100]\n",
        "              ,'gamma':[1,0.1,0.001]\n",
        "              ,'kernel':['linear','rbf']}\n",
        "\n",
        "grid_svm = GridSearchCV(svm.SVC(), param_grid, n_jobs=-1, refit=True, verbose=True)\n",
        "grid_svm.fit(X_train,y_train)\n",
        "\n",
        "print(\"Los mejores parámetros para la SVM y datos actuales son:\")\n",
        "print(grid_svm.best_params_)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  9.5min\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed: 23.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Los mejores parámetros para la SVM y datos actuales son:\n",
            "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a70gFYw8ZdrK",
        "colab_type": "text"
      },
      "source": [
        "Una vez hemos determinado los parámetros óptimos para el modelo y el conjunto de datos, debemos crear un nuevo modelo con estos parámetros y entrenarlo con el conjunto de datos correspondiente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-kJMf4GZdrK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5bdade5-8302-469e-ded5-67d9b1c11cda"
      },
      "source": [
        "clf = svm.SVC(C=100, gamma=0.001, kernel='rbf',verbose=True)\n",
        "\n",
        "# mdoel training\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# train and test evaluation\n",
        "y_train_pred = clf.predict(X_train)\n",
        "y_test_pred = clf.predict(X_test)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LibSVM]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9MiNnVdZdrM",
        "colab_type": "text"
      },
      "source": [
        "Finalmente, emplearemos el conjunto de test para obtener el valor de precisión (*accuracy*) conseguido por el modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prgdGQ-JZdrN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dbac2afa-71eb-48ab-9fbb-c5485774690b"
      },
      "source": [
        "print(\"Train accuracy is {}%\".format(np.mean(y_train_pred == y_train)*100))\n",
        "print(\"Test accuracy is  {}%\".format(np.mean(y_test_pred == y_test)*100))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy is 88.82342896174863%\n",
            "Test accuracy is  79.40573770491804%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}